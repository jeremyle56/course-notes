\section{Determinants}

\paragraph{Odd and Even Permutations}
If a permutation \(\sigma = [p_1, p_2, \dots, p_n]\) of \(\Omega_n\) contains \(k\) inversions then its sign, \(\sign(\sigma) = (-1)^k\). A permutation is called even or odd depending on whether the number of inversions is even or odd.

\paragraph{Determinant}
The determinant of an \(n \times n\) matrix \(A = (a_{ij})_{ij=1,\dots,n}\) is
\[\det(A) = \sum_{\sigma \in S_n} \sign(\sigma)a_{1\sigma(1)}a_{2\sigma(2)} \cdots a_{n\sigma(n)}.\]

\paragraph{Difference Product}
Define the \(n\)th difference product \(\Delta_n\) by 
\begin{align*}
  \Delta_n & = \prod_{i=1,j>1}^n (i-j) \\
  & = (1-2)(1-3) \dots (1-n)(2-3)(2-4) \dots ((n-1) - n)
\end{align*}

\paragraph{Signs Changed Equal Inversions}
For any \(\sigma \in \mathcal{S}_n, \sigma(\Delta_n) = \sign(\sigma)\Delta_n\).

\paragraph{Sign of Compositions}
If \(\alpha, \beta \in \mathcal{S}_n\) then \(\sign(\alpha \circ \beta) = \sign(\alpha)\sign(\beta)\), and \(\sign(\alpha^{-1}) = \sign(\alpha)\).

\paragraph{Transpositions are Odd}
Every transposition (i.e. swap of two elements) in \(\mathcal{s}_n\) is odd.

\paragraph{Properties of Determinant}
Let \(A \in M_{p,p}.\) Then
\begin{enumerate}
    \item \(\det(A) = \sum_{\sigma \in \mathcal{S}_n} \sign(\sigma)a_{\sigma(1)1}a_{\sigma(2)2}\cdots a_{\sigma(n)n}\).
    \item \(\det(A) = \det(A^T)\) and \(\det(A^*) = \bar{\det(A)}\)
    \item If any row or column of \(A\) is zero \(\det(A) = 0\).
    \item If a permutation is applied to the rows or columns of \(A\), then the determinant is multiplied by the sign of the permutation.
    \item If \(A\) has two rows or two columns the same, then \(\det(A) = 0\).
    \item If any row or column of \(A\) has a multiple of another row or column (respectively) added to it, the determinant is unchanged.
\end{enumerate}

\paragraph{Multilinear and Alternating}
If \(\det\) is considered as a map on the rows or columns of a matrix (that is, from \(p\) copies of \(\bF^p\) to \(\bF\)), then it is multilinear and alternating.

We note a useful special case of this last result, namely if any row or column of \(A\) is multiplied by a constant \(\alpha\), then the determinant is multiplied by \(\alpha\).

\paragraph{Matrix Minors}
For \(A \in M_{p,p}(\bF)\) let \(A_{ij}\) be the matrix obtained by deleting row \(i\) and column \(j\). We call \(A_{ij}\) the \((i,j)-\)minor of \(A\).

\paragraph{Determinant Minor Property}
Suppose that row \(i\) of matrix \(A \in M_{p,p}(\bF)\) is zero except for entry \(a_{ij}\). Then \[\det(A) = (-1)^{i+j}a_{ij}\det(A_{ij}).\]

\paragraph{Determinant of Triangular Maticies}
The determinant of an upper or lower triangular matrix is the product of its diagonal elements.

\paragraph{Elementary Row Operations and Matricies}
An elementary row operation on a matrix is one of the following:
\begin{enumerate}
    \item swapping two rows
    \item multiplying one row by a non-zero scalar
    \item adding a multiple of one row to another
\end{enumerate}
An elementary matrix is a matrix obtained from an identity matrix after an elementary row operation.

\paragraph{Invertible Matrices with Sequence of Elementary Matrices}
If \(A\) is invertible there is a sequence of elementary matrices \(E_1, E_2, \dots, E_k\) such that
\[A = E_1E_2\cdots E_k \text { and } \det(A) = \prod_{i=1}^k \det(E_i).\]

\paragraph{Determinant of Invertible Matrices}
A matrix \(A\) is invertible if and only if \(\det(A) \neq 0\).
If \(A\) is invertible, then \(\det(A^{-1}) = \frac{1}{\det(A)}\).

\paragraph{Determinant of Products}
For any two matrices \(A\) and \(B\), \(\det(AB) = \det(A)\det(B)\).

\paragraph{Zero Determinant}
A matrix \(A\) has determinant zero if and only if it has linearly dependent columns and hence if ando nly if it has linearly dependent rows.

\paragraph{Cofactor}
In matrix \(A\) the number \(c_{ij} = (-1)^{i+j}\det(A_{ij})\) is called the cofactor of element \(a_{ij}\).

\paragraph{Cofactor Expansion}
For any \(A \in M_{p,p}(\bF)\) and any fixed \(j\),
\[\det(A) = \sum_{i=1}^p a_{ij}c_{ij}.\]

\paragraph{Adjugate}
For \(A \in M_{p,p}(\bF)\) the adjugate (also called the classical adjoint and adjunct) of \(A, \adj(A)\) is the transpose of the matrix of cofactors \(\adj(A)_{ij} = c_{ji}\).

For an invertible matrix, \(A, A^{-1} = \dfrac{\adj(A)}{\det(A)}\).